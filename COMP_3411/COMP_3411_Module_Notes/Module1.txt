COMP 3411 - Module 1


Topics

What is an operating system?
Brief discussion of:
Batch systems
Multiprogramming
Time sharing
Parallel systems
Distributed systems
Clustered systems
Real-time systems
Embedded systems
Review of Computer System Structures:
Introduction to computer system architecture
Bootstrap
Interrupt
I/O structure
Storage structure and hierarchy
Hardware protection:
Dual mode
I/O protection
Memory protection
CPU protection
Learning Objectives
At the end of this Module, you will be able to:
Define what an operating system is.
The program that sits on top of the hardware and interfaces directly with the hardware. It is like a government, it does nothing useful on its own, but provides a framework within which others can do useful work. Some would argue that the operating system is the program which is always running (the kernel). Some are designed to make the most efficient possible use of hardware. Some are designed to be the most user friendly. Mobile device operating systems need to be able to provide the most productivity per battery life unit.

List operating systems of different types.

Define what multiprogramming, parallel processing, and time sharing are.
Define what real-time systems and embedded systems are.
Explain how an operating system starts when the user turns on the computer system.
It starts up by running the bootstrap program
Define what bootstrap is.
The initial program that runs on boot up. It knows where the kernel is and starts that process. It is stored in ROM or EEPROM. It initializes all aspect of the system, registers, controllers, memory contents
Explain how an interrupt can be handled.
It is handled by the operating system. In a dual mode system, the mode bit is switched to 0 to allow the kernel to execute priveledged instructions. The interupt typically points to an address in the interupt vector which routes to the desired interupt service routine. If the interupt has specific parameters, they are stored in registers, the stack, or in memory (with pointers to the memory stored as registers).  After the interupt is handled, the operating system switched the mode bit back to 1 (user mode) and passes control back to the user application
Explain how an interrupted program can resume later.
List storage types in the ascending order of access time.
Registers
cache
main meory
electronic disk
magnetic disk
optical disk
magnetic tapes
List the four types of hardware protection.
Explain how memory protection and CPU protection can be supported.
Definitions

Graceful Degredation – Providing service proportional to the level of surviving hardware. Ie if one processor out of 9 dies, we continue to get service at 90 percent full capacity

Asymmetric Multiprocessing – Each processor is assigned a specific task. A master processor controls the sytem in a master-slave relationship

Symmetric Multiprocessing (SMP) – Each processor peroms all tasks within the operating system. Processors are all peers. No master-slave relationship. Because they are seperate processors, one may be idle while another is over loaded which can cause inefficiencies. All modern Oss provide support for SMP

SunOS 4 – Assymetric multiprocessing OS

Solaris (SunOS 5) – A commercial version of UNIX designed by Sun Microsystems. Can be run on dozens of processors. Symetric Multiproccesing and can run on the same hardware as the SunOS 4

Uniform Memory Access (UMA) – Access to any RAM from any CPU is constant time

NonUniform Memory Access (NUMA) – Some parts of memory take longer to access than others. Operating systems attempt to limit the NUMA performance penalty through resource management

Blade Servers – Processor boards, i/o boards, and networking boards exist on the same chassis. All the boards boot independently and run individual operating systems. Essentially these serves consist of multiple independent multiprocessor systems

Clustered System – Multiple individual systems linked together via LAN or InfiniBand. Usually to provide high-availabilty service. A layer of cluster software runs on each node. Each node can monitor one or more other nodes and take over its tasks if that node goes down. This causes only a very small amount of down time to the user 

High-Availability Service – Service will continue even when one or more systems in a cluster fail. Generally obtained by adding a layer of redundancy

Beowulf Cluster – A cluster which provides high performance computing functionality by combining a whole bunch of cheap/free computing equipment and open source cluster software. Often used for high demand scientific computing.

Asymetric Clustering – One system sits in Hot Standby Mode which means it sits there and does nothing but monitor another system. When/if that system fails, it picks up where that system left off

Symetric Clustering – Two or more hosts are running applications and simultaneously monitoring each other. This is more efficient as it utilizes all of the available hardware

Parallelization – A method for writing applications which can take advantage of multiple processors. Essentially dividing up a program into components which can be run in parallel on individual computers

Parallel Clusters – Allow multiple hosts to access the same data on the shared storage. Most operating systems lack specific support for simultaneou data access, so this is done at the program level. (Eg. Oracle Real Application Cluster is a version of Oracle’s database designed to run on a parallel cluster.)

Distributed Lock Manager (DLM) – A function distributed in some cluster techknowlogy which provides access control and locking to allow shared access to data without the risk of conflicting operations.

Storage Area Networks (SAN) – Allow many systems to attach to a pool of storage. If applications and their data are stored on the SAN, then the cluster software can assign the application to run on any host that is attached to the SAN.

Multiprogramming – organizes jobs so that the CPU always has one to execute. Stops a single process from hogging the CPU or IO etc. Since main memory isn’t always big enough to hold all jobs, some are kept on disk in the job pool awaiing main memory space. If one job needs to wait for I/O before it can finish executing in CPU, CPU can move on and complete another job in the meantime. As long as at least one job is ready for the CPU, the CPU will be working.

Time Sharing (aka Multitasking) – An extension of multiprogramming inwhich the switching between jobs happens so frequently that the users can interact with programs while they are running. Requires an interactive computer system. Allows multiple users on one computer

Interactive Computer System – Provides direct communication between a user and the machine or the program, and provides feedback to the user very quickly. Usually less than one second

Time Sharing Operating System – Allows many users to interact with the computer at once, however the speed of switching between users is so quick that each user can believe they have the undivided attention of the computer

Job Scheduling – Making the decision of which job to bring into memory from the job pool.

CPU Scheduling – Making the decision of which job to execute first

Virtual Memory – A technique that allows for the execution of a process that is not entirely in main memory. Can run programs that are actually larger than physical memory

Exception (trap) – A software driven operating system interupt

Interupt Service Routine – Segments of code responsible for dealing with operating system interupts

Mode Bit – A single bit in the hardware of the computer which indicates the current mode (kernel-0 or user-1) 

Kernel Mode – When the computer is executing a task on behalf of the operating system

User Mode – When the computer is execuiting a task on behalf of a user program

System Call – how a user application can request service from the operating system. Usually takes the form of a trap to a specific location in the interrupt vector

Priviledged Instructions – Can only be executed in kernel mode

Timer – An operating system failsafe to ensure that a user program never has indefinite control ove the hardware. Before the operating system passes control back to the user program, it sets a time limit on how long the prgoram can have control for and if that time is exceeded, the timer interupts. This may lead to the operating system terminating the program, or giving it more time depending on the interupt service routine

Difference between program and process – A program is a passive entity like files store on a disk. A process is an active entity. A process riquires resources like CPU time, I/O and memory.

WORM – Write once, read many times

Cache – Faster than main memory. Allows the CPU to access information much faster than accessing from main memory. The cache is always the first place, the cpu looks when it is rying to access a piece of data.

Cache Coherency – Ensuring that all copies of a piece of data across multiple cahche instances are in sync with one another.

Memory Addressing Hardware – ensures thatno process can execute outside of its address space

Protection – Any mechanism for controlling access of processes or users to resources defined by a computer system

Security – Defends a system from internal and external attacks (virus, DDOS, etc)

Distributed Systems – Physically separate computers which are networked to provide access to various resources that the system maintains

FTP (File Transfer Protocol)– interactive command line tool for copying files between networked systems

NFS (Network File System)– a protocol that allows storage on a remote server to appear and behave exactly as if the storage were attached to the computer locally

Local Area Network (LAN) – links computers within a building

Wide Area Network (WAN) – links buildings cities or countries

Metropoliton Area Network (MAN) – Self explanitory

Small Are Network (SAN) – ie bluetooth connection over a few feet

Network Operating System – provides features such as file sharing across the network includes a communication scheme which allows computers to exchange messages. Computers act autonomously from each other, but they are aware of one another and exchange messages

Distributed Operation System – Less autonomous environment than Network Operating System. Different computers/operating systems communicate closely enough to provide the illusion that only a single operating system controls the network

Real Time Systems – Must complete tasks within a specific pre-defined time constraint. These systems are only said to be working if they execute correctly within the time limit.

Compute-Server System – Provides an interface to which a client can send requests to perform an action. The server executes the action and sends back results

File-Server System – Allows clients to create, update, read, and delete files (Ie a web server)

Peer-to-Peer system (P2P) – allows clients to share informtion and services with each other. Removes the server bottleneck. (Torrents)

Discovery Protocol – The method by which nodes in a P2P system get information on which other nodes can provide the service that they need

Load Balancers – Devices which disribute network connections among a pool of similar servers

Notes

Moving data from cache to cpu is a hardware function done independent of the CPU. Data transfer from disk to memory is controlled by the operating system

A single piece of data may exist simultaneously on disk, in memory, and in cache, and they may not always be in sync with one another. This can cause issues with multiprocessor environments and developers must take care that their programs are all grab the most recently updated version (typically the one at the highest level of memory hierarchy).

A computer may have multiple caches, so an update to a bit of data in one cache must be replicated accross to all other instances of that data in other caches. This becomes even more difficult in disributed systems where many instances of the same file may exist.

The UNIX I/O subsystem consists of :
 - A memory management component whih icludes buffering, caching, and spooling
 - A device driver interface 
- Drivers for specificmhardware devices

Only a device driver needs to kow the peculiarities of a specific device

Device-control registers are not accessible to users, so the integrity of teh various peripheral devices is protected

Security != protection

A computer creates a unique numerical security identifier (SID) for each user which is associates with all of the processes run by that user. What I see as “erik” is probably more like 39029400943 as far as the computer is concerned.

Users can belong to groups. Whether they can belong to multiple groups depends on operating system design. Groups also have unique identifiers which are associated with processes

Some operating systems treat network access as the same as file access and leave the specifics up to the network device driver. Other require users to specifically envoke network functions.

Multimedia files such as audio or video have the specific constraint that they must be streamed according to time restrictions (ie 30 fps)

Limitations of handheld computers: Less memory, less processing speed/power, less space for unique I/O




